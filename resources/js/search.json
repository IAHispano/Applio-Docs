[[{"l":"Home","p":["Applio Banner","Welcome to Applio - the ecosystem of voice cloning tools meticulously optimized for unrivaled power, modularity, and a user-friendly experience."]}],[{"i":"beginnerss-guide","l":"Beginners's Guide","p":["This section is oriented to users new to the world of AI voice conversion."]}],[{"l":"Frequent Doubts"},{"i":"what-is-applio-and-where-can-i-use-it","l":"What is Applio and where can I use it?","p":["Applio is the application that will allow us to create our own voices with AI or use existing voices. The program can be used installing it on your pc, or from the cloud through Google Colab (the best alternative for users who do not have a computer or have low resources).","As mentioned at the end of the text, to use applio locally on your computer you must have good hardware, especially if you want to clone a voice, what software do you need?. For Tranining applio requires at least a Nvidia Series 2000 (RTX) graphics card.","Keep in mind that if you want to use voices in your computer you can do it without having a super hardware."]},{"i":"how-do-i-install-applio","l":"How do I install Applio?","p":["Downloading applio is a very simple process, you can watch this video tutorial or view the installation section.","There is also a Google Colab alternative, if you do not have much idea how colab works or how to perform some actions within the environment you can have a look at the section of other alternatives."]}],[{"l":"Interface","p":["One of the main features of applio for user comfort is a simple to understand interface, but how can I make...?, this is what you will find here.","Make an inference/use voices; you can go to the inference section.","Make a Dataset, train a Voice Model: training Guide/ Create a Dataset","Use custom Pretrained (like Ov2 and RIN_E2): Load custom Pretrained","Use text-to-speech conversion for your Models: TTS Guide","How to use and understand the Tensorboard: Tensorboard Guide","Use the Audio Analyzer Tool for your datasets: Audio Analyzer Guide"]}],[{"l":"Make your first model","p":["Here you will learn the basics to create your first model.","Learn the basics of RVC/Applio: All about RVC/ How to use Applio.","Create your dataset: Guide on creating a dataset.","Learn how to easily extract vocals or audio Audio Isolating Guides.","Verify the sample rate of your dataset: Learn how to check it.","Train your model while monitoring TensorBoard: training Guide/ Tensorboard Guide.","Finally, test it: Inference Guide."]}],[{"l":"Make AI Cover","p":["Here you will learn how to make AI covers.","Separate the vocals from the instrumental: Audio Isolating Guides","Search or download the model you want to use: Applio Bot/ Applio Web","Open Applio and make the cover: Inference Guide/ Other Alternatives, then combine it with the instrumental and you’re done."]}],[{"l":"Get Started with Applio"}],[{"l":"Installation","p":["Click on run-applio.bat, that’s all.","Desactivate your antivirus and firewall to avoid missing dependencies.","Don't open the Applio.exe or run-applio.bat as an administrator.","Don't put it in a folder with privileged access.","Don't run the run-applio.bat as an administrator.","Don't run the run-install.bat as an administrator.","Download here","Download the .bat file of the latest version from GitHub repository","Download the zip here","Extract it","Extract the zip file","Here you will learn how to install Applio using commands in CMD.","Here you will learn how to install Applio via the official repository.","If you are having problems trying to run the executable, try with the Exe format.","If you are having problems trying to run the executable, try with the Zip format.","If you encounter an error during execution, you can try the precompiled (Exe) version of Applio.","If you encounter an error during execution, you can try the precompiled (Zip or Exe) version of Applio.","If you encounter an error during execution, you can try the precompiled (Zip) version of Applio.","In case you get a Windows message, just click on More information and then on Run anyway.","Installing Applio is a simple process, you can download and install Applio in different ways. If you are new to Applio we recommend installing the precompiled version (Zip or Exe) as it comes ready to use Applio.","Make sure that you place Applio inside a folder on C driver.","Make sure the path does not contain any spaces or special characters.","Open the executable so it can extract the program files","Run the run-applio.bat file","Run the run-applio.sh file","Run the run-install.bat, wait for it to download the necessary content","Run the run-install.sh, wait for it to download the necessary content"]},{"i":"how-to-update-applio","l":"How to update Applio?","p":["To update, it is necessary to delete the current Applio folder and reinstall it. Make sure to save your audios and models before deleting the current folder."]}],[{"i":"infer--download-models","l":"Infer & Download models","p":["Downloading a voice model is as simple as going to the Download tab.","Manual loading alternative: unzip the downloaded .zip file and drag the two files into the Drop files box. Now you can search for models from Applio by simply entering the character name to search in the Search Model section, then copy the model link or download it.","Applio can only download models from Google Drive, Huggingface, Applio Web, Discord, Yandex, Pixeldrain and Mediafire. Downloading files from mega may fail!, this is due to malfunction of the dependency."]},{"l":"How to infer","p":["When we have the model ready we will go back to the inference section.","Upload your audio and select it, make sure it is only vocals.","Click the Refresh button at the top right and select the downloaded/uploaded files in the Voice model and index file box.","Press Convert and you will have your inference done!","Place your audio files in a folder, copy and paste the path into the Input Folder, if you’d like, you can also specify the output path for the converted audios in the Output Folder.","Recommendation: having a clean acapella helps to get better results. but if the model downloaded in its name mentions the words rvmpe or crepe click on the advanced options box. Furthermore, this section has the following:","Look for better quality audio.","Your voice model needs more training or is overtraining.","Remove the reverb, double vocals and noise from your acapella, check the UVR 5 guide or MVSEP guide.","The dataset of your model contained noise, you need to clean the dataset.","Try advanced settings."]},{"i":"advanced-settings","l":"**Advanced Settings**","p":["Export Format: Select the format to export the audio.","Split Audio: Basically cuts the audio into parts to make the inference by parts and then joins them together.","Autotune: Apply a soft autotune to your inferences, recommended for singing conversions.","Clean Audio: Clean your audio output using noise detection algorithms, recommended for speaking audios.","Clean Strenght: The more you increase it the more it will clean up, but it will be more compressed.","Pitch: Adjust the tone of the model, for male it is - and female it is +. For male to female is -12 and female to male is +12.","Filter Radius: Applies respiration filtering to the results, the value represents the filter radius and respiration reduction to avoid artifacts.","Search Feature Ratio: It is the one in charge of controlling the index, the larger the ratio, the more single the dataset but it can result in artifacts, so it is better to leave it as it is by default.","Volume Envelope: Substitute or blend with the volume envelope of the output.","Protec Voiceless Consonants: Safeguard distinct consonants and breathing sounds to prevent electro-acoustic tearing and other artifacts.","Hop Length: Denotes the duration it takes for the system to transition to a significant pitch change. Smaller hop lengths require more time for inference and training but tend to yield higher pitch accuracy.","Pitch extraction algorithm: Select between rvmpe, crepe or other"]}],[{"l":"Training","p":["Training is only for NVDIA GPUs, If you don’t have a compatible GPU, the Training tab will be disabled.","How to use the Tensorboard for correct training? Check out the Tensorboard section.","upload your audio in .wav format using the Dataset Maker or setup it manually to applio/assets/datasets creating inside a folder for the program to read it.","don't know how to create a dataset?, check the dataset section","Once the model is named and the dataset selected press \"Prepocess Dataset\" and wait for the message in the CMD.","you can select one of the 3 available frequencies according to the audio (38k, 40k, 48k), this will help to avoid filtering out more artifacts or background noise.","don't know how to check sample rate?, check the sample rate section","Select an F0 method that suits your needs.","(optional) modify Hop lenght, lower value, higher smoothness of pitch change but slower training and vice versa.","Configure the training parameters according to your needs.","Save Every Epoch: Set this value between 10 and 50 to determine how often the model's state is saved during training.","Total Epochs: The number of epochs needed varies based on your dataset. Monitor progress using TensorBoard; typically, models perform well around 200-400 epochs.","Batch Size: Adjust based on your GPU's VRAM. For 8 GB VRAM, use a batch size between 6 and 8. Consider CUDA cores when experimenting with higher batch sizes."]},{"l":"Other Options","p":["Pitch Guidance: Gives variation of pitch.","Pretrained: Uses the RVC pretrained.","Save Only Lates: Save a single file with information.","Save Every Weights: Saves a D/G file of the process when a cycle of 'Save Every Epoch' is completed.","Custom Pretrained: Uses the Custom Pretrained that are loaded.","GPU Settings: Allows to choose GPUs (only for users who have more than one GPU).","Once configured, press 'Start training' to start the process, everything is registered in the CMD.","don’t forget to check TensorBoard while training your model., check the tensorboard section","Once training is completed, generate the index file by clicking the \"Train Feature Index\" button.","Now you can export your trained model directly from the Applio interface, go to the Export Model section in the train tab, click on the Refresh button and select the pth and the added index of the model to export.","(If you want to retrain, enter the same name of the model and locate in which stage the save files are left, enter a higher number of epoch.)","Your trained model is located in the logs/model folder, and the .pth files are in the logs/zips folder.","If you don’t have an NVIDIA GPU, you can try Applio Colab. Check the other alternatives section."]}],[{"l":"TTS","p":["We need to go to the TTS section in Applio.","Select our model with its respective index.","Select the model of TTS depending on the language you want and enter the text or add a txt file in the box below to convert.","Finally we click on convert and wait for the result","Applio also features ElevenLabs TTS. Check the Plugins section for more information."]}],[{"l":"Pretrained"},{"i":"what-are-pretraineds","l":"What are pretraineds?","p":["When it comes to training, you have two main options: building a model from the ground up or fine-tuning an already existing one. These pre-trained models are designed to streamline your training process, saving time and enhancing the overall quality of your results.","Simply put, the image illustrates that having a pre-trained model saves you effort during subsequent model training."]},{"i":"how-to-create-pretraineds","l":"How to create pretraineds?","p":["When creating a pretrained model, you have two primary options to consider.","Firstly, you can either initiate a fine-tuning process on another pretrained model, which could be one of the originals, or start building one from scratch.","Should you opt for building from scratch, the ideal approach involves gathering a substantial amount of moderately clean data; it doesn't necessarily have to be perfectly pristine. Subsequently, fine-tune this model with high-quality data.","An essential consideration is to construct datasets devoid of copyrighted material.","Alternatively, if you choose to fine-tune a pretrained model, the crux lies in the quality of the audio inputs. You can tailor it to a specific language, incorporate diverse speakers, and even integrate various accents. The customization possibilities are vast. However, it's crucial to strike a balance; avoid overtraining the pretrained model. The more effectively you fine-tune it now, the less training it will necessitate later during usage.","To embark on building a model from scratch, conduct standard training while disabling the Pretrained option. For fine-tuning, engage in ordinary training while loading the desired pretrained model to fine-tune it."]},{"i":"how-to-use-pretraineds","l":"How to use pretraineds?","p":["In the training tab, check the 'Custom Pretrained' box, upload the files, and select it in the Pretrained G/D Path boxes."]},{"i":"where-to-find-pretraineds","l":"Where to find pretraineds?"},{"l":"Ov2 Super by SimplCup","p":["Works well for small and English datasets. Additionally, it allows models to train with very few epochs compared to regular pretrains. This only supports 32k and 40k sample rates.","https://huggingface.co/ORVC/Ov2Super/tree/main"]},{"l":"RIN E3 by Mustar","p":["Yields good results with clean and English datasets, but it is more sensitive to noise. This only supports 40k sample rate.","https://huggingface.co/MUSTAR/RIN_E3/tree/main"]},{"l":"SnowieV3 by Mustar","p":["Works well with Russian datasets and also helps models of other languages to pronounce Russian well. Supports all the sample rates.","32k: SnowieV3.1-32k","40k: SnowieV3.1-40k","48k: SnowieV3.1-48k"]},{"l":"SnowieV3 X RIN_E3 by Mustar","p":["Works well with Russian or Japanese language datasets and also helps models of other languages to pronounce Russian or Japanese well. This only supports 40k sample rate.","Make sure to select the sample rate according to the sample rate of the custom pretraineds.","https://huggingface.co/MUSTAR/SnowieV3.1-X-RinE3-40K/tree/main======="]},{"i":"icon-slidersorder-e","l":"icon: sliders order: E"},{"l":"Custom Pretraineds","p":["In the training tab, check the 'Custom Pretrained' box, upload the files, and select it in the Pretrained G/D Path boxes."]},{"i":"what-are-custom-pretraineds","l":"What are custom pretraineds?","p":["Those are pretraineds trained by AI enthusiasts, unlike the original pretraineds, were created using long higher-quality datasets. Additionally, they yield better results in models."]},{"i":"ov2-super-by-simplcup-1","l":"Ov2 Super by SimplCup","p":["Works well for small and English datasets. Additionally, it allows models to train with very few epochs compared to regular pretrains. This only supports 32k and 40k sample rates.","https://huggingface.co/ORVC/Ov2Super/tree/main"]},{"i":"rin-e3-by-mustar-1","l":"RIN E3 by Mustar","p":["Yields good results with clean and English datasets, but it is more sensitive to noise. This only supports 40k sample rate.","https://huggingface.co/MUSTAR/RIN_E3/tree/main"]},{"i":"snowiev3-by-mustar-1","l":"SnowieV3 by Mustar","p":["Works well with Russian datasets and also helps models of other languages to pronounce Russian well. Supports all the sample rates.","32k: SnowieV3.1-32k","40k: SnowieV3.1-40k","48k: SnowieV3.1-48k"]},{"i":"snowiev3-x-rin_e3-by-mustar-1","l":"SnowieV3 X RIN_E3 by Mustar","p":["Works well with Russian or Japanese language datasets and also helps models of other languages to pronounce Russian or Japanese well. This only supports 40k sample rate.","Make sure to select the sample rate according to the sample rate of the custom pretraineds.","https://huggingface.co/MUSTAR/SnowieV3.1-X-RinE3-40K/tree/main","af1ef719174b1c782c1ed3dc586019044ec41fae:Get-Started/Pretrained.md"]}],[{"l":"Tensorboard","p":["Tensorboard is a series of graphs where we can monitor the progress of our model during training, but there are many graphs. We are only interested in the graph called 'g/total'. You can find this by clicking on 'inactive' and selecting 'scalars'. Then, go to the last page, where you will find it in the last graph."]},{"i":"how-tu-use-it","l":"How tu use it?","p":["Open TensorBoard by running the following command in your terminal or use the run-tensorboard.bat file:","Replace \"path/to/your/logs\" with the actual path to your TensorBoard logs.","Once TensorBoard is running, open your web browser and navigate to http://localhost:6006(or the address indicated in your terminal).","Click on the \"Scalars\" tab in TensorBoard.","Look for the \"g/total\" metric at the top to monitor the progress of your training.","TensorBoard Screenshot","This image provides a visual guide for locating the \"g/total\" metric within the \"Scalars\" tab.","Set the smoothing to 0.950 or 0.987 for a better view of the graph.","You can click on the ⚙️ to mark the option to reload data every 30 seconds.","Below each graph, there will be 3 buttons. The first one is to put it in full size, the second one is to deactivate the Y-axis and the last one is to adjust the data to the graph.","Uncheck the option to ignore outliers in chart scaling."]},{"l":"Lowest Point","p":["It’s when the graph goes to a point so low that it doesn’t happen again. During training, there will be several low points which you should test to find the indicated pth of your model and in this way prevent our model from being overtrained. To know which one to choose, we go to the lowest point and look at how many steps it has. Knowing this, we can search in the open cmd or colab notebook for the epochs with that step or the closest one from the save points."]},{"l":"Advanced Information","p":["Besides checking the loss/g/total, it’s necessary to monitor the loss/g/mel, loss/g/kl and loss/d/total graphs. If any of these values increase and don’t decrease again, it indicates overtraining."]}],[{"l":"Audio Analizer","p":["To use this tool, we go to the Extra section in the Audio Analyzer, drag our dataset and click on Get audio information.","don't understand how it works?, check the sample rate section"]}],[{"l":"Voice Blender","p":["Go to the Voice Blender section, place the Model Name of your new model, drag or upload the pth A and B files below, adjust the Audio Blend if desired, and click the Fusion button.","Your new pth file can be found in Applio/logs, ready for use in inference. Please note that being a mixed model, it won’t have an index."]}],[{"l":"Plugins"},{"i":"what-are-plugins-in-applio","l":"What are plugins in Applio?","p":["Plugins or extensions, as the name implies, allow you to add functions to applio without having to update the program.","How do I upload extensions to Applio?","Uploading Extensions to Applio is a simple process, download the extensions you want from here, go to the Plugins section and drag the .zip file to Plugin Installer, When you upload the file and refresh the interface you will see the section of the extension you have downloaded.","(Manual Upload: Drag and drop the files to Applio/Tabs/Plugins)"]},{"l":"Update Plugins","p":["Drag the updated zip file to the upload box or upload the folder to Applio/Tabs/Plugins/installed"]}],[{"l":"Extra","p":["Here you will find more things you can do in Applio."]},{"l":"View Model Information","p":["Go to the Extra section in the Processing section and place the model path in Path to model and click on View. This will display the model data in the command prompt (cmd)."]},{"l":"Settings","p":["Go to the Settings section where you can modify the following aspects:","Enable Applio presence on Discord.","Activate the ability to download models directly from the Applio Web by clicking on","Set your preferred theme.","Check the installed version of Applio.","Change the language of the Applio interface to your preference."]}],[{"l":"Other Alternatives","p":["(If you want to retrain insert the name of your model and enter a higher number of epochs)","(If you want to retrain place the name of your model in the Load a Backup cell and run it. Then, insert the name of your model and enter a higher number of epochs)","AutoBackup: Saves our trained model to our drive. Drive needs to be mounted first.","Click on \uD83D\uDCC1 and locate your trained model in the Applio/logs/model folder, and the .pth files are in the Applio/logs/zips folder.","Download Custom Pretrains: Allows direct downloading of custom pretrains to Applio.","Enter Applio Colab and just run the 2 cells.","Finally, the link to access the GUI will appear.","Finished Model: go to the Export Model section in the Train tab, click on the Refresh button and select the pth and the added index of the model to export. Finally, click on the Upload button, your model will be found in the ApplioExported folder ready to be used.","First you need to create a huggingface account.","First you should create an account on Paperspace","Go to the Gradient tab and click on the Create button:","Google Colab (Google Colaboratory) is a free cloud based platform that enables writing and executing Python code within an interactive notebook environment. It provides free access to computing resources, including CPUs, GPUs and TPUs from Google’s servers, making it particularly useful for machine learning tasks and data analysis. Additionally, Colab offers a Pro subscription, but it’s not highly recommended to pay for it when there are better alternatives available.","Hugging Face is a company specialized in artificial intelligence that has distinguished itself through its work in developing tools and models for natural language processing (NLP). This has made it one of the leading online communities and platforms for cutting edge NLP model research, development and distribution.","In this section, you will find the following options:","It should be noted that Gradio is banned from Colab, so it is preferable to use a secondary or new account to avoid a possible ban. Additionally, it is possible that Colab may disconnect after a few hours due to Google’s limitations.","Load a Backup: Used to load our model if we want to retrain it. Drive must be mounted.","Make sure to set the batch size according to the VRAM of your chosen GPU.","Manual (NOT RECOMENDED): click on \uD83D\uDCC1 in Colab and locate the added index of your model in the program/logs/model folder, and the .pth files are in the program/logs/zips folder so you can download them. If you want to save your model folder in your Drive, you just need to cancel the Start Applio cell and run the Mount Drive cell to be able to move it to your Google Drive.","Model to continue training: if you want to save all the archives of your model folder in your Drive, you just need to run the Mount Drive and AutoBackup cell before run Start Applio cell, your model folder will be found inside the ApplioBackup folder.","Mount Drive: Connects Colab to our Google Drive for performing backups.","Next time, you will only enter the last 3 commands.","Now type the following commands one at a time in the terminal; this is only for the first time:","Once the account is created, you will need to choose a Paperspace plan. To do this, click on Upgrade and select the one that suits your preference. The best option is the Pro plan.","Paperspace has joined DigitalOcean, so you can also pay with PayPal or Google Pay!.","Paperspace is a cloud platform that provides access to powerful virtual machines with dedicated GPU for software development, machine learning, artificial intelligence, and other applications that require substantial processing power. This has made it one of the most competent paid alternatives to Colab.","Place your audio in a folder on your Google Drive, run the Mount Drive cell in Colab and click on \uD83D\uDCC1 in Colab. Then navigate to your dataset folder, copy the path, it should look like this /content/drive/MyDrive/dataset folder and paste it into the dataset path.","Run tensorboard in another terminal, click on and enter the following commands:","Select a avaible GPU","Select the number of hours your computer will remain active. Then click on Start Notebook.","Select the template: Start from Scratch","Thanks to our team, we were able to bring Applio to other places for your convenience","Then a public link will be given to us where we can enter the interface.","Then enter Applio Huggingface Space and duplicate the space, that is all. If you don't want to use huggingface you can use Applo playground.","To load your dataset in Colab, there are two ways to do it:","To run this code in Colab, we have to press the keys Ctrl + Shift + i to open the developer tools option and the following window will open. In case another window is displayed, we can locate it by selecting the Console option, so in this way Colab will not disconnect during the separation process. First, we put Allow pasting, then we press enter and only then it will let us enter the code.","To save your model, there are three ways to do it:","Upload your audio in .wav format using the Dataset Maker or click on \uD83D\uDCC1 and setup it manually to Applio/assets/datasets creating inside a folder for the program to read it.","Upload your audio in .wav format using the Dataset Maker or click on \uD83D\uDCC1 in Colab and setup it manually to program/assets/datasets creating inside a folder for the program to read it.","You can pay by the hour for a dedicated GPU instead of using the default free ones or the paid plan.","You can train models while checking Tensorboard, do inference, or use TTS","You can't train models here because it only utilizes CPU.","You should know that Paperspace’s free plan is quite poor, and there’s nothing you can do about it. So, you should consider paying for a Pro or Growth plan.","You will be asked for account verification, so you will need to enter a phone number and input the received verification code.","You will need to clarify some additional account details before starting to use Paperspace."]}],[{"l":"Guides","p":["This section contains guides to help in the process of creating voices and other processes."]}],[{"l":"Audio Isolating","p":["To create a model, we first need to create our dataset. To do this, we need to separate the voices from the music. Here are some tools that can help you:","Download the music in .WAV format, or if it's in .mp3 format, convert it to .WAV."]},{"l":"Audio Isolating Tools"}],[{"l":"UVR","p":["5_Hp-Karaoke-UVR (to remove choruses from vocals)","BS Reformer","BS-Reformer-Viperx-1297 (the best to remove instrumental and vocals)","Choose Process Method select the type of models you need to use (MDX-Net or VR Arch) after that select the model and click Start Processing.","Demucs","Download and install Ultimate Vocal Remover.","Download the video of the song you want to use as a basis for creating the dataset or the AI cover:","Finally, look for your processed audio in the location you selected as output.","First, we go to the UVR Colab.","For Youtube: copy the song link from the search bar and paste it onto Cobalt.","Here you will learn how to Separate the Vocals and the Instrumental of songs with UVR.","htdemucs (to remove instrumental, vocals, drums, bass and other)","htdemucs_ft (to remove instrumental, vocals, drums, bass and other)","If you wish, you can change the Segment Size and the Overlap in case of MDX23C and MDX-NET, the windows size and the aggression setting for VR Arc to your preference or leave it as it is.","In case you get a Windows message, just click on More information and then on Run anyway.","In our Google Drive, we created the folder Separar where we will put our songs to separate, and Vocales where our already separated song will be stored.","MDX-NET models","MDX23C","MDX23C 8KFFT InstVoc HQ (one of the best to remove vocals and instrumental)","MDX23C 8KFFT instVoc HQ2 (one of the best to remove the instrumental and vocals)","MDX23C-InstVoc HQ (the best to remove the instrumental and vocals)","Now we go to the Vocales folder, there we find our separate audios, we download the audio with the name of the song-Vocals, in case you want the instrumental is song-Instrumental.","Now you can download the music that you want to separate from Colab, go to the YouTube Audio Downloader for Separation cell, just place the link of the song in video_url and song name in audio_name, then run that cell. Your song will be stored in the Separar folder that you created in your Drive.","Open Ultimate Vocal Remover and download the models, with which you can separate the voices and the instrumental parts into separate audios. For that, you will have to click here \uD83D\uDD27 and we go to the Download Center section.","Run the cell of your choice: BS Reformer, MDX23C, MDX-NET, VR ARCH, Demucs.","Run the Installation cell to start cloning the repository to the colab and mount drive.","Select the audio or song as input and choose the output folder for the instrumental or final vocals.","UVR-BVE-4B_SN-44100-1 (to separate 2 or more voices singing at the same time)","UVR-DeEcho-DeReverb (to remove reverb from vocals)","UVR-DeNoise (to remove noise from vocals)","UVR-MDX-NET Crowd HQ 1 (to remove crowd from vocals)","UVR-MDX-NET Voc FT (to remove the instrumental and vocals)","VR Arch models","You can change the type of wav or the MP3 bitrate in Additional settings, in Audio Format Settings.","You can choose the output format format of your separate audio.","You can select if you only want the Vocals Only, Instrumental Only, the vocals with No Reverb Only, No Crowd Only, No Noise Only or with those effects."]}],[{"l":"MVSEP","p":["After registering and logging in, select your audio or music to separate, and then choose the type of separation and the type of model if requested.","BanditPlus (to remove SFX, speech, music, effects)","BSReformer V2 (vocals, instrumental)","First, we go to the MVSEP page.","Here you will learn how to Separate the Vocals and the Instrumental of songs with MVSEP.","In some cases, you will see the option of aggressiveness, for better results you should set it to 0.5.","MDX B (vocals, instrumental)","MDX23C (to remove vocals and instrumental)","MVSep MelBand Reformer (to remove vocals and instrumental)","Then we click on the separate button and wait until it finishes to download our final vocals.","Ultimate Vocal Remover HQ (vocals, music)","Unlike doing it locally, here you will have to wait in a queue, this may take time depending on the queue at that moment.","UVR-BVE-4B_SN-44100-1 (to separate 2 or more voices singing at the same time)","UVR-DeEcho-DeReverb (to remove reverb from vocals)","UVR-DeNoise (to remove noise from vocals)","UVR-MDX-NET Voc FT (to remove instrumental and vocals)","ver 2024,04 (the best to remove instrumental and vocals)","viperx edition (to remove instrumental and vocals)"]}],[{"l":"KaraFan","p":["/ KaraF/ KaraFan_user","/ KaraFan","/ KaraFan_user","/ KaraFan_user / Multi_Song","/ Music","/ Results","After installation, you'll find new folders at the root of the folder you have chosen with the following structure :","Choose « Properties »","Click on the « OK » button","Donwload:","First, we go to the Google Colab.","First, we have to download and install Python.","Folder","For more information, visit the GitHub repository.","Function","Here you can put your audio files (or choose another one)","Here you will find your extracted audio files (or another one)","Here you will learn how to Separate the Vocals and the Instrumental of songs with KaraFan.","If you have installed Python 3.11 before WITHOUT using this Install.bat, you must uninstall it before ! Even those installed with the Microsoft Store !","If you want to test SDR with your own recipes","In our Google Drive, we created the folder Music where we will put our songs to separate, and Vocals where our already separated song will be stored","In the « General » tab, click on the « Unlock » button","Install.bat<-- Click to show, save it and rename to Install.bat.","Install.exe<-- The easiest way! (auto-extract the BAT).","Intall.zip<-- Bypass the Browser Security","Its is only for NVDIA GPUs.","Now place the settings you want to apply, try the ones you want the most, but if you want to effectively separate the instrumental or sounds from the vocals, I recommend the following settings:","Now we go to the Vocals folder and we will find a folder with the name of our song or audio. There we will find a list of audios, we download the audio with the name Vocal Final, in case you want the instrumental one that says Music Final.","Now we have to copy the path of your song that you want to separate and the path of the folder where the separated song will be stored.","Now, you can launch KaraFan.pyw by double-clicking on it.","On Windows 11, you must allow first the execution of the BAT file:","On your PC where you wish to store the KaraFan project and Go inside it.","Place your audio in the music folder and copy the path of your song that you want to separate and the path of the folder where the separated song will be stored.","Right-click on the file","Run Setup.py by double-clicking on it.","Run the cell by clicking on the white button. So that the repository can start to be cloned.","Simply Run the Setup.py file !","The Colab only lasts 30 minutes in execution. Additionally, it is possible that Colab may disconnect after a few hours due to Google’s limitations.","The first time you use it, it will start downloading the models you have selected in your drive in the KaraFan_user folder. If you keep this folder for the next time you want to use it, you will not need to download it again.","The main application","Then we click on the next cell This is it! to load the KaraFan interface.","To run this code in Colab, we have to press the keys Ctrl + Shift + i to open the developer tools option and the following window will open. In case another window is displayed, we can locate it by selecting the Console option, so in this way Colab will not disconnect during the separation process. First, we put Allow pasting, then we press enter and only then it will let us enter the code.","We click on Start and it will begin to separate the chosen song. At the end of the process, the message Processing DONE will appear at the end of the interface.","Where all the models are stored","Where config file & FFmpeg executable are saved","You must execute it with Administrator Rights."]}],[{"l":"Create datasets","p":["Here you will learn how to create a dataset to train your first RVC model."]}],[{"l":"How to create datasets"},{"i":"what-is-a-dataset","l":"What is a Dataset?","p":["A Dataset is a set of audio files compressed into a .zip file used by RVC for voice training.","First, we need to search for or download the audios of the person or character you want to create the model for","The audio must be in WAV or FLAC format and must be of good quality","The dataset should have a minimum duration of 10 minutes or a maximum of 30 minutes for better results","Make sure your dataset has the greatest variety of tones so that the model does not struggle when imitating certain tones.","Now we just need to separate the vocals from the instrumental.","don't know how to isolate audios?, check the audio insolation guide","After separating our audios, we open Audacity to edit them and do the following:","The dataset should only contain speech; any other type of sound should be removed or reduced, such as hisses, screams or breathing.","Finally, we export our already processed audio and it’s ready for training."]},{"l":"Noise Gate","p":["Is a tool that helps reduce background noise in an audio recording, first select your audio and go to the effect section under the Steve Daulton option and select noise gate. Then set the following parameters"]},{"l":"Truncating silence","p":["This tool is used to remove silences from our dataset, now go back to the effect section under the special option and select truncate silence. Then set the following parameters:"]}],[{"l":"Sample Rate","p":["Here you will learn how to see the sampling frequency of an audio."]},{"i":"what-is-sample-rate","l":"What is sample rate?","p":["Basically, it’s the frequency that our audio can reach, which is measured in KHz. If you choose an incorrect sample rate to train a type of sound unrelated to the voice, it can result in a poor model.","To do this, we need the program Spek. If you have Applio installed on your PC, you can check the audio analyzer section.","Drag your dataset into the program, and you’ll get the following image and information:","Sample rate","Duration of the audio","Number of Samples","Bits per Samples","Channels (Mono or Stereo)","Now that we’ve seen in the Spectrogram image that our audio has an audio frequency of 22050 KHz, we multiply it by two, and we would have our sample rate.","In case you get a frequency like 44100k, you should choose the one that is closest to that frequency."]}],[{"l":"Other guides","p":["In addition to Applio, we have a section of guides related to RVC or artificial intelligence. More information here. There you will find guides like:","W-Okada Voice Changer","Stable Cascade","Illusion Difusion AI","DeepFaceLab","LM Studio","Stable Video Diffusion-XT","Stable Diffusion","Whisper"]}],[{"l":"Voice Models","p":["You can access voice models on various Discord servers dedicated to AI, such as AI Hispano.","Additionally, you can explore the capabilities of the official Applio bot for more information. Click here to learn more about this bot!"]}],[{"l":"Applio Bot","p":["The bot is capable of searching models within a database of over +500k functional RVC voice models, consider using Applio Bot. It offers the convenience of collecting models from multiple servers and provides an easy to use interface."]},{"l":"Invitation"},{"l":"How to use Applio Bot","p":["Type the command /search, enter the model name you want to search for, Click on \uD83D\uDCE4Download to download the model or right click to get the model link, that’s all."]}],[{"l":"Applio Web","p":["If you are not closely related to discord or some other reason you can choose to use the web version of the Applio, search for any RVC voice model in our database.","Choose the model you wish to use and click on to get the link or on to download it, then go to the Download tab of Applio."]}],[{"l":"Developers","p":["This section is oriented to users who are interested in our work."]}],[{"l":"Applio API","p":["Create, experiment and develop; fast and public."]},{"i":"what-is-the-applio-api","l":"What is the Applio API?","p":["Applio API is the key that allows request and access in a few clicks a quantity of +20k voice models created using RVC technology totally free. This is done through our database, with which the Applio Bot and the Website works.","How to access and use the Applio API?","Go to the Applio website, register, and once you have done so, you can go to the API section and create a key."]}],[{"l":"Projects","p":["\"I have programming knowledge and I would like to contribute to applio projects, is there any possibility?\"","Of course, all projects like Applio Bot, Applio, even the docs themselves are public and open source so that anyone can contribute improvements or features to them!, you can find them at https://github.com/IAHispano"]}],[{"l":"Report an Error","p":["\"I have an error when using Applio, is there any way to report it or find a solution?\"","Yes, you can report a bug by going to the issues section, click on \"new issues\", send an image / full text of the Applio CMD and comment how you get the error (in which part, what action perform when getting the message).","You can also go to the report a bug section in Applio to easily record what is happening."]}],[{"l":"Frequently Asked Questions","p":["We've curated a comprehensive list of frequently asked questions or resolved errors to address any queries you might have. If you still have doubts or need further assistance, please don't hesitate to reach out to us via our official Discord server."]}],[{"l":"General","p":["Questions and errors about RVC/Applio in general"]}],[{"l":"Errors","p":["Common general errors in RVC/Applio."]},{"i":"dependencies","l":"**Dependencies**","p":["In the conda installation method, Applio is installed in a conda environment. This enviroment has all the dependencies needed to run RVC/Applio so you don't need to install anything else."]},{"i":"error-downloading-miniconda","l":"**Error Downloading Miniconda**","p":["If there are issues automatically downloading Miniconda, download it manually and install it."]},{"i":"conda-error-building-wheels","l":"**Conda Error Building Wheels**","p":["If Conda shows an error related to the \"Wheels\" dependency, check that Visual Studio Build Tools are installed. This requirement it should be installed semi automatically by the installer."]},{"i":"tensorboard-or-dependency-error","l":"**Tensorboard or dependency error**","p":["If an error related to Tensorboard occurs, it's likely that no dependencies were installed correctly. Review if you have the latest installer version.","Also, please check if you have done any of the following:","If you did, please reinstall applio in a directory without spaces or non ASCII characters in the path. (For example your C: drive root)","If you did, please reinstall applio with the antivirus disabled.","If you did, please open it without administrator privileges."]},{"i":"situation-with-google-colab","l":"**Situation with Google Colab**","p":["Unfortunately, Google Colab is currently unavailable as Google has taken measures to restrict access to Colab services, including Applio. Thanks to our team, we have been able to bring Applio back. More information here."]},{"i":"ffmpeg-error-utf8-error","l":"**FFmpeg error/utf8 error**","p":["Ensure paths are free of special characters."]},{"i":"connection-error","l":"**Connection Error**","p":["Ensure the console (black command line window) is open."]},{"i":"webui-popup-expecting-value-line-1-column-1-char-0","l":"**WebUI popup 'Expecting value: line 1 column 1 (char 0)**","p":["Disable system LAN proxy/global proxy and refresh."]},{"i":"cuda-error-cuda-out-of-memory","l":"**Cuda error/Cuda out of memory**","p":["Adjust batch size for training; for inference, modify settings in config.py. Consider upgrading the GPU if needed."]},{"i":"file-memory-error-when-training","l":"**File/memory error(when training)**","p":["Reduce \"Number of CPU threads\" or pre-cut training set to shorter audio files."]},{"i":"error-about-llvmlite-dll","l":"**Error about llvmlite.dll**","p":["Install vc_redist.x64.exe for Windows."]},{"i":"runtimeerror-the-expanded-size-of-the-tensor","l":"**RuntimeError: The expanded size of the tensor...**","p":["Delete smaller-sized wav files, then click \"train the model\" and \"train the index.\""]},{"i":"runtimeerror-the-size-of-tensor-a-must-match","l":"**RuntimeError: The size of tensor a must match...**","p":["Avoid changing the sampling rate mid-training. If necessary, change the exp name and train from scratch or copy pitch and features folders to accelerate training."]},{"i":"the-filename-directory-name-or-volume-label-syntax-is-incorrect","l":"**The filename, directory name, or volume label syntax is incorrect**","p":["Make sure to correctly set the path for your dataset before training. Remember that the dataset should not be in a zip file within the Applio/assets/datasets folder."]},{"i":"indexerror-list-index-out-of-range","l":"**IndexError: list index out of range**","p":["Make sure to use the same sample rate when retraining or when selecting a custom pretrain."]},{"i":"alternative","l":"**Alternative**","p":["If all else fails, download the precompiled (Zip or Exe) version. This will bring everything ready to start applio without the need to perform the installation."]}],[{"l":"Info","p":["Common questions and information about RVC/Applio in general"]},{"i":"how-to-train-and-infer-without-the-webui","l":"**How to train and infer without the WebUI?**","p":["Link: Training and Inference without WebUI"]},{"i":"how-to-share-a-model-how-to-use-others-models","l":"**How to share a model/How to use others models?**","p":["Share the pth file in the weights folder, not the one in logs. Future versions will use a zip file. Do not copy large pth files; use the ckpt tab to extract a smaller model for sharing. Compress it into a zip and upload it to Drive or Huggingface if you want to publish your model in Ai Hispano, go to the \uD83D\uDCE9 publish-a-model section and execute the /model command and fill in the corresponding data of your model"]},{"i":"test-previous-model-and-continue-training","l":"**Test previous model and continue Training**","p":["select one of the .pth generated file in Applio/Logs/zips(you need to have the index previously generated for best results) or Save via model extraction at the bottom of the ckpt processing tab.","Add data to a new path, process dataset, extract features, copy G and D files from the previous experiment, and continue training.","when increasing the number of audio, it is recommended to retrain the model so as not to have a mixture of datasets."]}],[{"l":"Others"},{"l":"Check Build Tools Installed","p":["How to Verify the Correct Installation of Visual Studio Build Tools","If you encounter issues with the installation of Visual Studio Build Tools, you can ensure they are installed correctly by following these steps:","Open the Visual Studio Installer. If you haven't installed it yet, you can download it here.","Confirm that the displayed screen resembles the one shown below (or a similar one for a different version):","Visual Studio Installer","2.1. If the required components are not installed, navigate to the \"Available\" tab. Click on the \"Install\" button next to \"Visual Studio Build Tools 2022\" and select both \"Desktop development with C++\" and \".NET Desktop Buildtools\" by clicking on their respective icons:","If the screen resembles the one above, click on the \"Modify\" button. Ensure that both \"Desktop development with C++\" and \".NET Desktop Buildtools\" options are selected. If they are not, click on them, and then click the \"Install\" button:"]}],[{"l":"RVC","p":["Questions about RVC."]},{"i":"what-is-rvc","l":"What is RVC?","p":["RVC (Retrieval-Based Voice Conversion) is one of the is one of the Ai voice cloning techniques using speech synthesis."]},{"i":"what-are-the-requirements-for-rvc-applio","l":"What are the requirements for RVC/Applio?","p":["The minimum required for local training is an Nvidia RTX series 20 graphics card with 8GB of VRAM to train models, in the case of inference you only need to have a decent CPU and at least 4GB of VRAM. If you have a Celeron processor, it would be better to look at other alternatives."]},{"i":"can-i-use-rvc-applio-on-a-mac","l":"Can I use RVC/Applio on a Mac?","p":["Yes, but only for inference. besides, the installation should be done as if it were on Linux."]},{"l":"Dataset","p":["A Dataset is a set of audio files compressed into a .zip file used by RVC for voice training."]},{"i":"is-a-dataset-the-same-as-a-model","l":"Is a Dataset the same as a Model?","p":["No, a Dataset is the set of audio used for training, while a Model is the result of that training."]},{"l":"Added index","p":["The added index contains the compressed dataset and is responsible for controlling the tones of the model at the time of inference."]},{"l":"Pth","p":["It is the one that contains all the data from the trained model that will serve us to make inference."]},{"l":"Epoch","p":["An Epoch is the number of iterations performed during training to complete one full cycle of your dataset. For example, if you have a dataset of 200 audio samples and you set a batch_size of 10, 10 audio samples will be processed in each iteration. To process all 200 audio samples, you will need to perform 20 iterations in total. This complete cycle is referred to as one epoch."]},{"l":"F0 extraction methods","p":["pm: Provides a fast result at the cost of vague tone processing.","Harvest: Better replication of tones, slower model and often gives errors.","Dio: Similar to PM processing, provides fast processing with better transition in tones.","Crepe/crepe-tiny: Contains an elaborate processing of pitch changes, compared to the previous ones this one does not distort in magnitude. (Crepe is to be able to modify the value of pitch processing (Hop Lenght), lower value will induce a better result but slower and vice versa.)","Rmvpe: Model with Crepe and PM features, fast and quality tone processing with low probability of distortion.","Fcpe: Fpce is a alternative hybrid method that works similarly to f0 with the difference of a slightly more optimized processing and taking less context from the input audio for a \"particular\" conversion."]},{"l":"Batch Size","p":["The batch size is the amount of GPU that will be used to train the model. The larger the batch size, the shorter the training duration. It is recommended to use multiples of 4 as the batch size, although the most common is 8, as it gives the AI time to learn correctly without rushing."]},{"l":"Inference","p":["is the process where an audio is transformed by the voice model."]},{"l":"Artifacting","p":["Is when the inference output sounds robotic, distorted, with background noise and with fails when trying to modulate words."]},{"l":"Pretrained","p":["It is a model trained with several sets of long-duration audios that will serve as a basis for training the models in RVC."]},{"l":"Overtraining","p":["It’s when the TensorBoard graph starts to rise and never comes back down. An overtrained model will sound robotic, muffled, and won’t be able to articulate words well. For more information check the Tensorboard section."]},{"l":"G and D","p":["They are responsible for storing the training data of the model. Generative learns to replicate results similar to the original. Discriminator tries to distinguish real data from those created by the generator."]}],[{"l":"Applio Specific","p":["Specific questions about Applio-RVC-Fork"]},{"i":"what-are-the-key-improvements-of-applio-rvc-fork-over-the-original-rvc-repository","l":"What are the key improvements of Applio-RVC-Fork over the original RVC repository?","p":["Applio-RVC-Fork introduces several enhancements over the original RVC repository, including an f0 inference algorithm overhaul, Paperspace integration, access to Tensorboard, CLI functionality, etc."]},{"i":"how-has-the-f0-inference-algorithm-been-improved-in-applio","l":"How has the f0 inference algorithm been improved in Applio?","p":["Applio features a comprehensive overhaul of the f0 inference algorithm, introducing alternative methods like pyworld dio, crepe, and torchcrepe crepe-tiny model."]},{"i":"what-is-the-significance-of-paperspace-integration-in-applio","l":"What is the significance of Paperspace integration in Applio?","p":["Applio seamlessly integrates with Paperspace, offering features such as Paperspace arguments for sharing Gradio links, and a dedicated make file tailored for Paperspace users."]},{"i":"what-cli-functionality-does-applio-introduce","l":"What CLI functionality does Applio introduce?","p":["Applio introduces command-line interface (CLI) functionality, enabling users to use the --is_cli flag in infer-web.py for CLI system usage."]},{"i":"what-changes-have-been-made-to-the-ui-in-applio-for-both-inference-and-training","l":"What changes have been made to the UI in Applio for both inference and training?","p":["In the inference interface, there is a complete redesign for an enhanced user experience, including audio recording, drop-down menus for file selection, and an advanced settings section."]}],[{"l":"LICENSE","p":["=======================================================================","Adapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.","Adapter's License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.","Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.","Attribution-NonCommercial 4.0 International","Attribution.","By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.","Copyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.","Creative Commons Attribution-NonCommercial 4.0 International Public License","Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.","Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.","Creative Commons may be contacted at creativecommons.org.","Creative Commons may be contacted at creativecommons.org. Attribution-NonCommercial 4.0 International","Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.","Effective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.","Exceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.","for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;","For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.","For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.","For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.","For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.","if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and","License grant.","Licensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.","Licensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.","Licensor means the individual(s) or entity(ies) granting rights under this Public License.","No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.","NonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.","Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.","Other rights.","Section 1 -- Definitions.","Section 2 -- Scope.","Section 3 -- License Conditions.","Section 4 -- Sui Generis Database Rights.","Section 5 -- Disclaimer of Warranties and Limitation of Liability.","Section 6 -- Term and Termination.","Section 7 -- Other Terms and Conditions.","Section 8 -- Interpretation.","Sections 1, 5, 6, 7, and 8 survive termination of this Public License.","Share means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.","Sui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.","The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.","The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.","This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.","To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.","TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.","UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.","Using Creative Commons Public Licenses","Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:","Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:","You means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.","You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.","Your exercise of the Licensed Rights is expressly made subject to the following conditions."]}]]